{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent with Tools\n",
    "\n",
    "In this notebook we present a sample multi-agent architecture, where the agent orchestating the answer calls world knowledge, a tool implemented using another agent that iteratively searches the web. Additionally, a simple tool to get Youtube links based on a query is included, so that the agent's recommendations can include visual data as well.\n",
    "\n",
    "> If you don't have `pytube` installed, you need to install it inside the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case pytube is not installed\n",
    "!pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gptstonks.multiagents.graphs import GraphAgentWithTools\n",
    "from gptstonks.multiagents.tools import WorldKnowledgeTool, YoutubeSearchTool\n",
    "from llama_index.llms.openai import OpenAI as LlamaIndexOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your OpenAI key, as function calling is used in all the agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the tools to search the Internet and YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llamaindex_llm = LlamaIndexOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, max_tokens=2048)\n",
    "world_knowledge_tool = WorldKnowledgeTool.from_llamaindex_llm(\n",
    "    llamaindex_llm=llamaindex_llm,\n",
    "    use_openai_agent=True,\n",
    "    verbose=True,\n",
    "    tool_description=\"Useful to retrieve any information related to music and trends: songs, what users like, recent updates, etc.. Input must be a complete question of the information to retrieve.\",\n",
    "    search_tool_description=\"Useful to search any type of information using DuckDuckGo.\",\n",
    "    wikipedia_tool_description=\"Useful to get information about named entities.\",\n",
    "    auto_multistep_query_engine_qa_template=\"Context information is below.\\n---------------------\\n{context_str}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query. Write very detailed answers.\\nQuery: {query_str}\\nAnswer: \",\n",
    "    auto_multistep_query_engine_refine_template=\"You are an expert Q&A system that strictly operates in two modes when refining existing answers:\\n1. **Rewrite** an original answer using the new context.\\n2. **Repeat** the original answer if the new context isn't useful.\\nNever reference the original answer or context directly in your answer.\\nWrite very detailed answers.\\nWhen in doubt, just repeat the original answer.\\nNew Context: {context_msg}\\nQuery: {query_str}\\nOriginal Answer: {existing_answer}\\nNew Answer: \",\n",
    "    auto_multistep_query_engine_stepdecompose_query_prompt=\"The original question is as follows: '{query_str}'\\nWe must answer this question from a knowledge source, by dividing it into simpler questions. Context information for the knowledge source is provided below, as well as previous reasoning steps.\\nGiven the context and previous reasoning, return a relevant question that can be answered from the context and helps answer the original question. This relevant question can be the same as the original question if it is simple, or this question can represent a step towards answering the overall question. It must be relevant to answer the original question.\\nIf we cannot extract more information from the context, provide 'None' as the answer, but NEVER if the previous reasoning is 'None' too.\\n\\nQuestion: {query_str}\\nKnowledge source context: {context_str}\\nPrevious reasoning: {prev_reasoning}\\nNew question (can't be 'None'): \"\n",
    ")\n",
    "youtube_search_tool = YoutubeSearchTool.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the agent graph with OpenAI function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature=0, max_tokens=2048, model_kwargs={\"top_p\": 0.8})\n",
    "graph = GraphAgentWithTools(\n",
    "    model=llm,\n",
    "    tools=[world_knowledge_tool, youtube_search_tool],\n",
    "    prompt_main_agent=ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"Forget everything you knew. You are an expert in creating music playlists for a wide variety of users. You provide very detailed and clearly structured answers. You always start by searching with world knowledge.\",\n",
    "            ),\n",
    "            (\"user\", \"{input}\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    ),\n",
    ").define_basic_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the multi-agent architecture to solve our complex task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = await graph.ainvoke({\n",
    "    \"input\": \"I really like the group AJR. What other groups would you recommend? Provide a Youtube links for reference.\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the final response!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res[\"context_messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
