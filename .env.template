# Uncomment to run with debugging
DEBUG_API=true

# System message for the agent
LLM_CHAT_MODEL_SYSTEM_MESSAGE="You are GPTStonks Chat, a financial chatbot developed by GPTStonks that democratizes the access to financial data.\n"

# ID of the embedding model to use
# Example provided with local model, use "default" for OpenAI model
AUTOLLAMAINDEX_EMBEDDING_MODEL_ID=local:BAAI/bge-base-en-v1.5

# LLM to use. Format provider:model_id, where model_id is dependent on the provider.
# Example provided with gpt-3.5-turbo-0125
LLM_MODEL_ID=openai:gpt-3.5-turbo-0125
OPENAI_API_KEY=sk-...

# Context window when using llama.cpp models and local models
LLM_LLAMACPP_CONTEXT_WINDOW=8000
AUTOLLAMAINDEX_LLM_CONTEXT_WINDOW=8000

# Randomness in the sampling of the posterior of the LLM
# 0 - greedy sampling, 1 - posterior without modification
LLM_TEMPERATURE=0

# Max tokens to sample from LLM
LLM_MAX_TOKENS=512

# Description of the OpenBB chat tool
OPENBBCHAT_TOOL_DESCRIPTION="useful to get historical pricing data. Input should be the concrete data to retrieve, in natural language."
WORLD_KNOWLEDGE_TOOL_DESCRIPTION="useful to solve complex or incomplete financial questions and to search on the Internet current events, news and concrete financial datapoints."

# Path to the Vector Store Index (VSI)
AUTOLLAMAINDEX_VSI_PATH="vsi:./gptstonks_api/data/openbb_v4.1.0_historical_vectorstoreindex_bgebaseen"

# Template for the QA (Question-Answer) format
AUTOLLAMAINDEX_QA_TEMPLATE="You must write Python code to solve the query '{query_str}'. You must use only one of the functions below and store its output in a variable called `res`.\n---------------------\n{context_str}\n---------------------\nWrite the Python code between '```python' and '```', using only one of the functions above. Do not use `print`."

# MongoDB URI
MONGO_URI=mongodb://mongo:27017

# MongoDB database name
MONGO_DBNAME=mongodb
